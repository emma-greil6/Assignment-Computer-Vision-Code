{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862b269-6b53-4f1e-b383-bd65c785aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAM 2025\n",
    "\n",
    "# Question 1 – Segmentation des gumballs par Watershed\n",
    "#1.a.i Prétraitement\n",
    "#Chargement et affichage de l’image RGB\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gumballs = cv2.imread('gumballs.jpg')\n",
    "gumballs_rgb = cv2.cvtColor(gumballs, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(gumballs_rgb)\n",
    "plt.title('Image RGB – Gumballs')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Choix du canal couleur\n",
    "#Le canal rouge est le plus adapté car les gumballs rouges, oranges et roses y apparaissent avec une intensité élevée.\n",
    "red_channel = gumballs_rgb[:,:,0]\n",
    "plt.imshow(red_channel, cmap='gray')\n",
    "plt.title('Canal rouge')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Lissage\n",
    "#Un flou gaussien est utilisé pour réduire le bruit tout en conservant des contours lisses.\n",
    "blur = cv2.GaussianBlur(red_channel, (5,5), 1)\n",
    "plt.imshow(blur, cmap='gray')\n",
    "plt.title('Image lissée (Gaussian Blur)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Seuillage\n",
    "_, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "plt.imshow(binary, cmap='gray')\n",
    "plt.title('Image binaire après seuillage')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Morphologie\n",
    "#Ouverture pour supprimer le bruit + fermeture pour combler les trous.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "clean = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "plt.imshow(clean, cmap='gray')\n",
    "plt.title('Image binaire nettoyée')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 1.a.ii Segmentation par Watershed\n",
    "#Détection des graines\n",
    "dist = cv2.distanceTransform(clean, cv2.DIST_L2, 5)\n",
    "_, sure_fg = cv2.threshold(dist, 0.5*dist.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "plt.imshow(sure_fg, cmap='gray')\n",
    "plt.title('Graines pour Watershed')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Application du Watershed\n",
    "unknown = cv2.subtract(clean, sure_fg)\n",
    "_, markers = cv2.connectedComponents(sure_fg)\n",
    "markers = markers + 1\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "markers = cv2.watershed(gumballs, markers)\n",
    "\n",
    "#Résultat final\n",
    "result = gumballs_rgb.copy()\n",
    "result[markers == -1] = [255,0,0]\n",
    "\n",
    "plt.imshow(result)\n",
    "plt.title('Résultat final Watershed')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#1.b Discussion\n",
    "#Le watershed est efficace pour séparer des objets en contact mais sensible au bruit et au mauvais choix de graines. Les variations de couleur et d’illumination compliquent la segmentation.\n",
    "\n",
    "#Question 2 – Réalité augmentée : détection, suivi et remplacement\n",
    "#2.a.i Détection par Template Matching\n",
    "frame1 = cv2.imread('frame1.png')\n",
    "frame1_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "template = cv2.imread('template.jpg',0)\n",
    "frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "res = cv2.matchTemplate(frame1_gray, template, cv2.TM_SQDIFF)\n",
    "min_val, _, min_loc, _ = cv2.minMaxLoc(res)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "bbox = frame1_rgb.copy()\n",
    "cv2.rectangle(bbox, min_loc, (min_loc[0]+w, min_loc[1]+h), (255,0,0), 2)\n",
    "plt.imshow(bbox)\n",
    "plt.title('Détection du damier')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 2.a.ii Suivi par Optical Flow\n",
    "corners = cv2.goodFeaturesToTrack(frame1_gray, 36, 0.01, 5)\n",
    "\n",
    "frame2 = cv2.imread('frame2.png')\n",
    "frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "lk_params = dict(winSize=(15,15), maxLevel=2,\n",
    "criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "\n",
    "p2, st, err = cv2.calcOpticalFlowPyrLK(frame1_gray, frame2_gray, corners, None, **lk_params)\n",
    "# Choix des paramètres : fenêtre modérée pour déplacements lents, pyramide pour gérer les variations d’échelle\n",
    "\n",
    "#2.a.iii Remplacement du damier\n",
    "graphic = cv2.imread('graphic.jpg')\n",
    "graphic_rgb = cv2.cvtColor(graphic, cv2.COLOR_BGR2RGB)\n",
    "graphic_resized = cv2.resize(graphic_rgb, (w,h))\n",
    "\n",
    "\n",
    "frame2_rgb = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "frame2_rgb[min_loc[1]:min_loc[1]+h, min_loc[0]:min_loc[0]+w] = graphic_resized\n",
    "\n",
    "\n",
    "plt.imshow(frame2_rgb)\n",
    "plt.title('Réalité augmentée – Damier remplacé')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Question 3 – CNN et ResNet50\n",
    "#3.a CNN CIFAR-10 avec Early Stopping\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train,x_test = x_train/255.0, x_test/255.0\n",
    "y_train,y_test = to_categorical(y_train,10), to_categorical(y_test,10)\n",
    "\n",
    "model = Sequential([\n",
    "Conv2D(8,(5,5),activation='relu',input_shape=(32,32,3)),\n",
    "MaxPooling2D((2,2)),\n",
    "Conv2D(16,(5,5),activation='relu'),\n",
    "MaxPooling2D((2,2)),\n",
    "Flatten(),\n",
    "Dense(512,activation='relu'),\n",
    "Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=2, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train,y_train,epochs=3,batch_size=64,\n",
    "validation_data=(x_test,y_test),callbacks=[early])\n",
    "\n",
    "#3.b ResNet50 – Images de mains\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "model.summary()\n",
    "\n",
    "def preprocess_img(path):\n",
    "img = image.load_img(path, target_size=(224,224))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "return preprocess_input(img)\n",
    "\n",
    "img1 = preprocess_img('hand1.jpg')\n",
    "img2 = preprocess_img('hand2.jpg')\n",
    "\n",
    "pred1 = decode_predictions(model.predict(img1), top=3)[0]\n",
    "pred2 = decode_predictions(model.predict(img2), top=3)[0]\n",
    "#Discussion : Les prédictions peuvent être peu pertinentes car les mains ne font pas partie des classes ImageNet.\n",
    "\n",
    "#3.c Fine-tuning (théorie)\n",
    "#   Geler les premières couches\n",
    "#   Ré-entraîner les couches finales\n",
    "#   Ajuster le learning rate\n",
    "#   Plus le dataset cible est différent, plus il faut dégeler de couches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
