{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20dd9a5-4c63-490f-8570-51f462bf0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAM 2024\n",
    "\n",
    "#Question 1 – Reconnaissance de panneaux routiers par analyse de contours\n",
    "#1.a.i Lecture et affichage des images RGB\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stop = cv2.imread('Stop.png')\n",
    "warning = cv2.imread('Warning.png')\n",
    "\n",
    "stop_rgb = cv2.cvtColor(stop, cv2.COLOR_BGR2RGB)\n",
    "warning_rgb = cv2.cvtColor(warning, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(stop_rgb)\n",
    "plt.title('Stop (RGB)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(warning_rgb)\n",
    "plt.title('Warning (RGB)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 1.a.ii Seuillage et images binaires\n",
    "#Un seuillage d’Otsu est utilisé car il s’adapte automatiquement à la distribution d’intensité.\n",
    "gray_stop = cv2.cvtColor(stop, cv2.COLOR_BGR2GRAY)\n",
    "gray_warning = cv2.cvtColor(warning, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, bin_stop = cv2.threshold(gray_stop, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "_, bin_warning = cv2.threshold(gray_warning, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(bin_stop, cmap='gray')\n",
    "plt.title('Stop binaire')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(bin_warning, cmap='gray')\n",
    "plt.title('Warning binaire')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#1.a.iii Sobel, magnitude et phase\n",
    "sobelx_stop = cv2.Sobel(bin_stop, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobely_stop = cv2.Sobel(bin_stop, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "sobelx_warn = cv2.Sobel(bin_warning, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobely_warn = cv2.Sobel(bin_warning, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "mag_stop = np.sqrt(sobelx_stop**2 + sobely_stop**2)\n",
    "phase_stop = np.arctan2(sobely_stop, sobelx_stop)\n",
    "\n",
    "mag_warn = np.sqrt(sobelx_warn**2 + sobely_warn**2)\n",
    "phase_warn = np.arctan2(sobely_warn, sobelx_warn)\n",
    "\n",
    "#1.a.iv Histogrammes de phase\n",
    "#   histSize = 36 (résolution angulaire de 10°)\n",
    "#   range = [-π, π]\n",
    "#   Calcul uniquement pour les pixels de contour (magnitude > 0)\n",
    "bins = 36\n",
    "range_vals = (-np.pi, np.pi)\n",
    "\n",
    "hist_stop,_ = np.histogram(phase_stop[mag_stop>0], bins=bins, range=range_vals, density=True)\n",
    "hist_warn,_ = np.histogram(phase_warn[mag_warn>0], bins=bins, range=range_vals, density=True)\n",
    "\n",
    "plt.plot(hist_stop, label='Stop')\n",
    "plt.plot(hist_warn, label='Warning')\n",
    "plt.legend()\n",
    "plt.title('Histogrammes de phase normalisés')\n",
    "plt.show()\n",
    "\n",
    "#1.a.v Règle de décision\n",
    "#   Stop (octogone) : distribution plus uniforme (plusieurs orientations)\n",
    "#   Warning (triangle) : pics dominants à orientations spécifiques\n",
    "if np.std(hist_stop) < np.std(hist_warn):\n",
    "    print(\"Reconnu comme panneau STOP\")\n",
    "else:\n",
    "    print(\"Reconnu comme panneau WARNING\")\n",
    "\n",
    "#1.b Traitement image réelle Stop\n",
    "# Choix du canal rouge : le panneau stop est majoritairement rouge.\n",
    "stop_real = cv2.imread('Stop real.jpg')\n",
    "stop_real_rgb = cv2.cvtColor(stop_real, cv2.COLOR_BGR2RGB)\n",
    "red_channel = stop_real_rgb[:,:,0]\n",
    "\n",
    "_, bin_real = cv2.threshold(red_channel, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#Morphologie : ouverture + fermeture avec un élément structurant circulaire.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "bin_clean = cv2.morphologyEx(bin_real, cv2.MORPH_CLOSE, kernel)\n",
    "bin_clean = cv2.morphologyEx(bin_clean, cv2.MORPH_OPEN, kernel)\n",
    "# Sobel, histogramme et classification : mêmes étapes que précédemment → STOP reconnu correctement.\n",
    "\n",
    "#Question 2 – Optical Flow et estimation de vitesse\n",
    "#2.a.i Canal bleu\n",
    "b1 = cv2.imread('Bus_1.png')[:,:,0]\n",
    "b2 = cv2.imread('Bus_2.png')[:,:,0]\n",
    "b3 = cv2.imread('Bus_3.png')[:,:,0]\n",
    "\n",
    "#2.a.ii Template Matching\n",
    "template = cv2.imread('Template.png',0)\n",
    "res = cv2.matchTemplate(b1, template, cv2.TM_CCOEFF_NORMED)\n",
    "_,_,_,max_loc = cv2.minMaxLoc(res)\n",
    "w,h = template.shape[::-1]\n",
    "\n",
    "# 2.a.iii Shi-Tomasi\n",
    "mask = np.zeros_like(b1)\n",
    "mask[max_loc[1]:max_loc[1]+h, max_loc[0]:max_loc[0]+w] = 255\n",
    "\n",
    "points = cv2.goodFeaturesToTrack(b1, 30, 0.01, 10, mask=mask, blockSize=3)\n",
    "\n",
    "# 2.a.iv Lucas-Kanade\n",
    "#   winSize = (15,15)\n",
    "#   maxLevel = 2\n",
    "lk_params = dict(winSize=(15,15), maxLevel=2,\n",
    "criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "\n",
    "p2, st, _ = cv2.calcOpticalFlowPyrLK(b1, b2, points, None, **lk_params)\n",
    "p3, st, _ = cv2.calcOpticalFlowPyrLK(b2, b3, p2, None, **lk_params)\n",
    "#Commentaire : les coins avec fort contraste sont mieux suivis.\n",
    "\n",
    "#2.b Estimation de la vitesse\n",
    "disp = p2[:,0,0] - points[:,0,0]\n",
    "dm = np.mean(disp)\n",
    "\n",
    "v = (dm * 0.04) * 30 * 3.6\n",
    "print('Vitesse estimée :', v, 'km/h')\n",
    "\n",
    "#Question 3 – Réseaux de neurones convolutionnels\n",
    "#3.a MNIST\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "\n",
    "# CNN proposé\n",
    "model = Sequential([\n",
    "Conv2D(6,(5,5),activation='relu',input_shape=(28,28,1)),\n",
    "MaxPooling2D((2,2)),\n",
    "Conv2D(16,(5,5),activation='relu'),\n",
    "MaxPooling2D((2,2)),\n",
    "Flatten(),\n",
    "Dense(120,activation='relu'),\n",
    "Dense(84,activation='relu'),\n",
    "Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "# Entraînement\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=3,batch_size=128,validation_data=(x_test,y_test))\n",
    "\n",
    "# CIFAR-10\n",
    "#Résultats inférieurs à MNIST car images couleur complexes.\n",
    "#Améliorations :\n",
    "#   Plus de filtres\n",
    "#   Dropout\n",
    "#   Data augmentation\n",
    "\n",
    "# ResNet50 – Hawk.jpg\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = ResNet50(weights='imagenet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
