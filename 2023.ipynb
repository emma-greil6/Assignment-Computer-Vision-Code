{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccfcf2-3112-42f8-9147-046905f5da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAM 2023 ANSWER\n",
    "\n",
    "#Question 1 – Détection, classification et localisation de crayons colorés\n",
    "#1.a Détection des pointes de crayons\n",
    "#i. Lecture et affichage de l’image RGB\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "img = cv2.imread('Pencils.jpg')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Image RGB – Crayons')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# ii. Affichage des canaux RGB\n",
    "channels = ['Rouge','Vert','Bleu']\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(3):\n",
    "plt.subplot(1,3,i+1)\n",
    "plt.imshow(img_rgb[:,:,i], cmap='gray')\n",
    "plt.title(channels[i])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#iii. Choix du canal\n",
    "#Le canal bleu offre le meilleur contraste entre les pointes (blanches et bleues) et le fond, avec peu de faux positifs du fond.\n",
    "\n",
    "#iv. Seuillage d’Otsu\n",
    "blue = img_rgb[:,:,2]\n",
    "_, binary = cv2.threshold(blue, 0, 1, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "plt.imshow(binary, cmap='gray')\n",
    "plt.title('Image binaire – Otsu')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# v. Commentaire\n",
    "#Otsu segmente correctement la majorité des pointes, mais certaines pointes bleues sombres sont partiellement segmentées en raison d’un contraste plus faible.\n",
    "\n",
    "#1.b Distinction entre pointes blanches et bleues\n",
    "#i. Histogramme du canal rouge\n",
    "red = img_rgb[:,:,0]\n",
    "values = red[binary==1]\n",
    "\n",
    "\n",
    "plt.hist(values, bins=256, range=(0,256))\n",
    "plt.xlabel('Intensité du canal rouge')\n",
    "plt.ylabel('Nombre de pixels')\n",
    "plt.title('Histogramme du canal rouge (zones des pointes)')\n",
    "plt.show()\n",
    "\n",
    "# ii. Séparation par seuillage\n",
    "#Un seuil intermédiaire (ex. 150) sépare efficacement les pointes blanches (intensité élevée) des pointes bleues.\n",
    "th = 150\n",
    "white_tips = np.logical_and(binary==1, red > th).astype(np.uint8)\n",
    "blue_tips = np.logical_and(binary==1, red <= th).astype(np.uint8)\n",
    "\n",
    "#iii. Morphologie\n",
    "#Ouverture + fermeture avec un élément structurant elliptique 5×5.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "white_clean = cv2.morphologyEx(white_tips, cv2.MORPH_CLOSE, kernel)\n",
    "blue_clean = cv2.morphologyEx(blue_tips, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#1.c Localisation par centroides\n",
    "#i. Extraction des centroides\n",
    "_, _, _, centroids_w = cv2.connectedComponentsWithStats(white_clean)\n",
    "_, _, _, centroids_b = cv2.connectedComponentsWithStats(blue_clean)\n",
    "\n",
    "#ii. Visualisation\n",
    "out = img_rgb.copy()\n",
    "for c in centroids_w[1:]:\n",
    "cv2.circle(out, (int(c[0]),int(c[1])), 5, (0,0,0), -1)\n",
    "for c in centroids_b[1:]:\n",
    "cv2.circle(out, (int(c[0]),int(c[1])), 5, (0,255,0), -1)\n",
    "\n",
    "plt.imshow(out)\n",
    "plt.title('Centroides des pointes')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Question 2 – Détection de véhicules et infractions\n",
    "#2.a Détection de voitures par Haar Cascade\n",
    "cars = cv2.imread('Cars.jpg')\n",
    "cars_rgb = cv2.cvtColor(cars, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cascade = cv2.CascadeClassifier('cars.xml')\n",
    "detections = cascade.detectMultiScale(cars, scaleFactor=1.01)\n",
    "\n",
    "out = cars_rgb.copy()\n",
    "for (x,y,w,h) in detections:\n",
    "cv2.rectangle(out,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "plt.imshow(out)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "#Commentaire : beaucoup de faux positifs dus à un scaleFactor trop faible.\n",
    "#Reglage des parametres : detections = cascade.detectMultiScale(cars, scaleFactor=1.2, minNeighbors=5, minSize=(30,30))\n",
    "\n",
    "#2.b Détection du marquage BUS (Template Matching)\n",
    "template = cv2.imread('Template.jpg')\n",
    "template_rgb = cv2.cvtColor(template, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "res = cv2.matchTemplate(cars_rgb, template_rgb, cv2.TM_SQDIFF)\n",
    "min_val, _, min_loc, _ = cv2.minMaxLoc(res)\n",
    "\n",
    "#2.c Détection d’infractions\n",
    "for (x,y,w,h) in detections:\n",
    "if abs(x - min_loc[0]) < 150:\n",
    "cv2.rectangle(out,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "#Question 3 – Réseaux de neurones\n",
    "#3.a CNN MNIST\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train,x_test = x_train/255.0, x_test/255.0\n",
    "x_train = x_train[...,None]\n",
    "x_test = x_test[...,None]\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "\n",
    "model = Sequential([\n",
    "Conv2D(6,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "MaxPooling2D((2,2)),\n",
    "Conv2D(16,(3,3),activation='relu'),\n",
    "MaxPooling2D((2,2)),\n",
    "Flatten(),\n",
    "Dense(120,activation='relu'),\n",
    "Dense(84,activation='relu'),\n",
    "Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=2,batch_size=32,validation_data=(x_test,y_test))\n",
    "\n",
    "#iv–v Discussion\n",
    "#   Learning rate trop élevé : divergence\n",
    "#   Trop faible : convergence lente\n",
    "#   Underfitting : faible accuracy entraînement et validation → modèle trop simple\n",
    "\n",
    "#3.b InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "model = InceptionV3(weights='imagenet')\n",
    "\n",
    "def prep(path):\n",
    "img = cv2.imread(path)\n",
    "img = cv2.resize(img,(299,299))\n",
    "img = preprocess_input(img.astype(np.float32))\n",
    "return np.expand_dims(img,0)\n",
    "\n",
    "pred = model.predict(prep('Test1.jpg'))\n",
    "decode_predictions(pred, top=3)\n",
    "#Discussion : variations d’angle, d’éclairage et d’occlusion expliquent la baisse de performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
